Una vez llegados a este punto, intentaremos analizar si hemos conseguido cumplir los objetivos que motivaron este proyecto, y en caso contrario, imaginar y proponer cómo podrían cumplirse con trabajos futuros.

En primer lugar podemos concluir que hemos conseguido desarrollar un sistema en Java altamente adaptable para la extracción de datos desde Twitter con ayuda de la API que Twitter nos proporciona para dicho uso. Hemos conseguido esta versatilidad gracias a la implementación de los filtros para acotar las extracciones (el conjunto de datos a extraer es totalmente personalizable), las abstracción y modularización durante el desarrollo (desarrollar nuevos tipos de tareas asíncronas y de reportes o gráficas es sencillamente abarcable y tiene un mínimo impacto), las distintas opciones intercambiables que hemos ofrecido para visualizar los resultados, el hecho de aprovechar el soporte para los distintos idiomas de Twitter, ...

En cuanto a los datos extraídos, podemos concluir que la visualización, edición e integración de estos es también bastante versátil. El modelo de datos diseñado hace que resulte muy fácil obtener todo tipo de métricas que se nos ocurran a través de consultas tan intuitivas como las consultas SQL. El hecho de poder exportar los datos en formatos estándares (XML, CSV, ...) nos permite además poder tratar estos datos fuera de nuestro sistema (como en Excel, R, Matlab,...).

La interfaz gráfica que hemos obtenido dota a nuestro sistema de una simplicidad y una facilidad de uso que, una vez instalado, lo hace accesible a cualquier tipo de usuario no necesariamente experto en sistemas informáticos, en parte gracias al sistema de diálogos informativos que guía todas las acciones del usuario durante todo el proceso. Esto es un resultado a valorar, ya que esta herramienta también podría ser atractiva para investigadores, trabajadores de las ciencias de la información, asociaciones de la sociedad civil, trabajadores de marketing y publicidad...

En cuanto a la interpretación de los resultados para nuestro caso de uso concreto, podemos concluir que el volumen de tweets extraído es bastante más bajo de lo personalmente esperaba (un total de casi 5000 tweets diferentes en 7 meses). Esto puede deberse a dos factores: o bien no hemos configurado las extracciones de la manera más óptima para el objetivo que teníamos, o bien realmente el volumen de tweets sobre la participación ciudadana en Madrid es bajo. En este sentido, sería interesante en trabajos futuros investigar si con otra configuración de filtros o con el uso de algoritmos como el ``algoritmo de adaptación de palabras clave refinado''\cite{Criado2013} se obtendrían resultados más voluminosos.

Debido a este bajo volumen apenas ha sido necesaria la utilización de los segundos credenciales de la API que habíamos obtenido (la tasa de extracción sólo se ha sobrepasado tres veces desde que se inició la extracción, y siempre debido a reinicio consecutivos del servidor que causaban que las tareas se reiniciaran varias veces y lanzasen un número elevado de peticiones en un corto período de tiempo). Sin embargo, cabe destacar que en otros contextos el hecho de poder rotar los credenciales es una funcionalidad clave (una sola consulta de tweets conteniendo ``Madrid'' puede sobrepasar la tasa de extracción).

Es muy destacable que de los tweets obtenidos tan solamente un usuario (concretamente desde un gimnasio en Pozuelo de Alarcón) tenía activada la inclusión de la geolocalización del dispositivo en la publicación. Esto conlleva que no hemos podido inferir conclusiones sobre las distribución geográfica de los intereses de los usuarios. En otros contextos en los que obtuviésemos más geolocalizaciones sería muy interesante utilizar las coordenadas para delimitar zonas a las que puedan pertenecer los tweets.

Con los datos que tenemos, podemos concluir que (salvo un único pico el 30 de enero aparentemente debido a una campaña en Twitter sobre sanidad pública y los hospitales de Madrid) el flujo de tweets es bastante constante (unos 15 tweets al día), si bien es cierto que se percibe cierta reactividad en cadena (períodos sin tweets tras los cuales un único tweet provoca el interés de otros usuarios que también publican en los momentos siguientes). Esto explica las aristas en la gráfica que nos muestra el volumen de tweets en el tiempo. Por otro lado, nuestro sistema nos dice que entre Diciembre de 2018 y Junio de 2019 los temas que más se mencionan en los tweets obtenidos son la participación ciudadana (comentarios sobre iniciativas, propuestas, etc.), los partidos políticos, el ayuntamiento y la gestión pública y la movilidad. El resto de temas o bien empatan en volumen a un nivel más bajo como ``Medio ambiente'', o bien directamente ni se mencionan, como ´´Accesibilidad'').

Finalizaremos hablando sobre la perspectivas en el futuro. Por un lado como ya se ha mencionado opino que sería interesante centrar futuros esfuerzos en el algoritmo utilizado para seleccionar los tweets para obtener más volumen de datos. Para otros casos en los que haya muchos ruido entre los datos descargados (no ha sido nuestro caso), se podrían desarrollar tareas asíncronas que fuesen limpiando las extracciones desde el servidor. Sería también interesante portabilizar la GUI (bien a una versión web o bien añadiendo aplicación nativa para dispositivos móviles, lo cual es factible con JavaFX), para facilitar aún mas el acceso y la gestión del sistema.

Para concluír, diremos que nuestro punto de vista es que en este mundo cada día más conectado a las redes sociales y en el cual la información comienza a convertirse en un bien muy apreciado, este tipo de herramientas serán de gran utilidad para la tecnología, la sociología, los mercados, y todo tipo de entidades que podamos imaginar.